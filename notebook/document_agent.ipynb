{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Obtaining file:///workspaces/ag2\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Checking if build backend supports build_editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing editable metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: asyncer==0.0.8 in /home/vscode/.local/lib/python3.10/site-packages (from pyautogen==0.7.3) (0.0.8)\n",
      "Requirement already satisfied: diskcache in /home/vscode/.local/lib/python3.10/site-packages (from pyautogen==0.7.3) (5.6.3)\n",
      "Requirement already satisfied: docker in /home/vscode/.local/lib/python3.10/site-packages (from pyautogen==0.7.3) (7.1.0)\n",
      "Requirement already satisfied: fast-depends<3,>=2.4.12 in /home/vscode/.local/lib/python3.10/site-packages (from pyautogen==0.7.3) (2.4.12)\n",
      "Requirement already satisfied: numpy in /home/vscode/.local/lib/python3.10/site-packages (from pyautogen==0.7.3) (1.26.4)\n",
      "Requirement already satisfied: openai>=1.58 in /home/vscode/.local/lib/python3.10/site-packages (from pyautogen==0.7.3) (1.60.2)\n",
      "Requirement already satisfied: packaging in /home/vscode/.local/lib/python3.10/site-packages (from pyautogen==0.7.3) (24.2)\n",
      "Requirement already satisfied: pydantic<3,>=2.6.1 in /home/vscode/.local/lib/python3.10/site-packages (from pyautogen==0.7.3) (2.10.6)\n",
      "Requirement already satisfied: python-dotenv in /home/vscode/.local/lib/python3.10/site-packages (from pyautogen==0.7.3) (1.0.1)\n",
      "Requirement already satisfied: termcolor in /home/vscode/.local/lib/python3.10/site-packages (from pyautogen==0.7.3) (2.5.0)\n",
      "Requirement already satisfied: tiktoken in /home/vscode/.local/lib/python3.10/site-packages (from pyautogen==0.7.3) (0.7.0)\n",
      "Requirement already satisfied: websockets<15,>=14 in /home/vscode/.local/lib/python3.10/site-packages (from pyautogen==0.7.3) (14.2)\n",
      "Requirement already satisfied: anyio<5.0,>=3.4.0 in /home/vscode/.local/lib/python3.10/site-packages (from asyncer==0.0.8->pyautogen==0.7.3) (4.8.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/vscode/.local/lib/python3.10/site-packages (from openai>=1.58->pyautogen==0.7.3) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/vscode/.local/lib/python3.10/site-packages (from openai>=1.58->pyautogen==0.7.3) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /home/vscode/.local/lib/python3.10/site-packages (from openai>=1.58->pyautogen==0.7.3) (0.8.2)\n",
      "Requirement already satisfied: sniffio in /home/vscode/.local/lib/python3.10/site-packages (from openai>=1.58->pyautogen==0.7.3) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /home/vscode/.local/lib/python3.10/site-packages (from openai>=1.58->pyautogen==0.7.3) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /home/vscode/.local/lib/python3.10/site-packages (from openai>=1.58->pyautogen==0.7.3) (4.12.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/vscode/.local/lib/python3.10/site-packages (from pydantic<3,>=2.6.1->pyautogen==0.7.3) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /home/vscode/.local/lib/python3.10/site-packages (from pydantic<3,>=2.6.1->pyautogen==0.7.3) (2.27.2)\n",
      "Requirement already satisfied: requests>=2.26.0 in /home/vscode/.local/lib/python3.10/site-packages (from docker->pyautogen==0.7.3) (2.32.3)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /home/vscode/.local/lib/python3.10/site-packages (from docker->pyautogen==0.7.3) (2.3.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /home/vscode/.local/lib/python3.10/site-packages (from tiktoken->pyautogen==0.7.3) (2024.11.6)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/vscode/.local/lib/python3.10/site-packages (from anyio<5.0,>=3.4.0->asyncer==0.0.8->pyautogen==0.7.3) (1.2.2)\n",
      "Requirement already satisfied: idna>=2.8 in /home/vscode/.local/lib/python3.10/site-packages (from anyio<5.0,>=3.4.0->asyncer==0.0.8->pyautogen==0.7.3) (3.10)\n",
      "Requirement already satisfied: certifi in /home/vscode/.local/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai>=1.58->pyautogen==0.7.3) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in /home/vscode/.local/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai>=1.58->pyautogen==0.7.3) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/vscode/.local/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.58->pyautogen==0.7.3) (0.14.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/vscode/.local/lib/python3.10/site-packages (from requests>=2.26.0->docker->pyautogen==0.7.3) (3.4.1)\n",
      "Building wheels for collected packages: pyautogen\n",
      "  Building editable for pyautogen (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pyautogen: filename=pyautogen-0.7.3-py3-none-any.whl size=15111 sha256=5469cbf50af2638d2607a6ba21b21d5796fa91fab16ebef3a556a2cf9c04fc75\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-3mqj8vm3/wheels/11/f5/85/6c46c8d75fe0fb9b7ae9617f7f96f2006a97883188c6e9abf1\n",
      "Successfully built pyautogen\n",
      "Installing collected packages: pyautogen\n",
      "  Attempting uninstall: pyautogen\n",
      "    Found existing installation: pyautogen 0.7.3\n",
      "    Uninstalling pyautogen-0.7.3:\n",
      "      Successfully uninstalled pyautogen-0.7.3\n",
      "Successfully installed pyautogen-0.7.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -e /workspaces/ag2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import autogen\n",
    "\n",
    "config_list = autogen.config_list_from_json(\n",
    "    \"../OAI_CONFIG_LIST\",\n",
    "    filter_dict={\n",
    "        \"model\": [\"gpt-4o\"],\n",
    "    },\n",
    ")\n",
    "os.environ[\"OPENAI_API_KEY\"] = config_list[0][\"api_key\"]\n",
    "\n",
    "llm_config = {\n",
    "    \"config_list\": config_list,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vscode/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from typing import Literal, Optional, Union\n",
    "\n",
    "from autogen import ConversableAgent\n",
    "from autogen.agentchat.contrib.rag.parser_utils import docling_parse_docs\n",
    "from autogen.tools.tool import Tool\n",
    "\n",
    "parser_tool = Tool(\n",
    "    name=\"docling_parse_docs\",\n",
    "    description=\"Use this tool to parse and understand text.\",\n",
    "    func_or_tool=docling_parse_docs,\n",
    ")\n",
    "\n",
    "\n",
    "DEFALT_DOCLING_PARSER_PROMPT = \"\"\"\n",
    "You are an expert in parsing and understanding text. You can use this tool to parse various documents and extract information from them.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class ParserAgent(ConversableAgent):\n",
    "    def __init__(\n",
    "        self,\n",
    "        llm_config: Optional[Union[dict, Literal[False]]] = llm_config,\n",
    "    ):\n",
    "        super().__init__(\n",
    "            name=\"DoclingParserAgent\",\n",
    "            system_message=DEFALT_DOCLING_PARSER_PROMPT,\n",
    "            human_input_mode=\"NEVER\",\n",
    "            llm_config=llm_config,\n",
    "        )\n",
    "\n",
    "        parser_tool.register_for_llm(self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:autogen.agentchat.contrib.rag.document_utils:Error when checking if /workspaces/ag2/test/agentchat/contrib/graph_rag/Toast_financial_report.pdf is a valid URL: Invalid URL.\n",
      "INFO:autogen.agentchat.contrib.rag.document_utils:Detected file. Returning file path...\n",
      "INFO:docling.document_converter:Going to convert document batch...\n",
      "/home/vscode/.local/lib/python3.10/site-packages/docling/models/easyocr_model.py:58: UserWarning: Deprecated field. Better to set the `accelerator_options.device` in `pipeline_options`. When `use_gpu and accelerator_options.device == AcceleratorDevice.CUDA` the GPU is used to run EasyOCR. Otherwise, EasyOCR runs in CPU.\n",
      "  warnings.warn(\n",
      "INFO:docling.utils.accelerator_utils:Accelerator device: 'cpu'\n",
      "INFO:docling.utils.accelerator_utils:Accelerator device: 'cpu'\n",
      "INFO:docling.pipeline.base_pipeline:Processing document Toast_financial_report.pdf\n",
      "INFO:docling.document_converter:Finished converting document Toast_financial_report.pdf in 24.73 sec.\n",
      "INFO:autogen.agentchat.contrib.rag.parser_utils:Document converted in 24.73 seconds.\n",
      "INFO:autogen.agentchat.contrib.rag.parser_utils:Document Toast_financial_report.pdf converted.\n",
      "Saved markdown output to:  /workspaces/ag2/output_dir_path\n",
      "INFO:autogen.agentchat.contrib.rag.parser_utils:Saving HTML table to  /workspaces/ag2/output_dir_path/Toast_financial_report-table-1.html\n",
      "INFO:autogen.agentchat.contrib.rag.parser_utils:Saving HTML table to  /workspaces/ag2/output_dir_path/Toast_financial_report-table-2.html\n",
      "INFO:autogen.agentchat.contrib.rag.parser_utils:Saving HTML table to  /workspaces/ag2/output_dir_path/Toast_financial_report-table-3.html\n",
      "INFO:autogen.agentchat.contrib.rag.parser_utils:Saving HTML table to  /workspaces/ag2/output_dir_path/Toast_financial_report-table-4.html\n"
     ]
    }
   ],
   "source": [
    "results = docling_parse_docs(\n",
    "    \"/workspaces/ag2/test/agentchat/contrib/graph_rag/Toast_financial_report.pdf\", \" /workspaces/ag2/output_dir_path\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mUserAgent\u001b[0m (to DoclingParserAgent):\n",
      "\n",
      "could you parse /workspaces/ag2/test/agentchat/contrib/graph_rag/Toast_financial_report.pdf and output to /workspaces/ag2/output_dir_path?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mDoclingParserAgent\u001b[0m (to UserAgent):\n",
      "\n",
      "\u001b[32m***** Suggested tool call (call_zb7cxuWeEmflKxds0HHmx9HV): docling_parse_docs *****\u001b[0m\n",
      "Arguments: \n",
      "{\"input_file_path\":\"/workspaces/ag2/test/agentchat/contrib/graph_rag/Toast_financial_report.pdf\",\"output_dir_path\":\"/workspaces/ag2/output_dir_path\"}\n",
      "\u001b[32m***********************************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> NO HUMAN INPUT RECEIVED.\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION docling_parse_docs...\n",
      "Call ID: call_zb7cxuWeEmflKxds0HHmx9HV\n",
      "Input arguments: {'input_file_path': '/workspaces/ag2/test/agentchat/contrib/graph_rag/Toast_financial_report.pdf', 'output_dir_path': '/workspaces/ag2/output_dir_path'}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:autogen.agentchat.contrib.rag.document_utils:Error when checking if /workspaces/ag2/test/agentchat/contrib/graph_rag/Toast_financial_report.pdf is a valid URL: Invalid URL.\n",
      "INFO:autogen.agentchat.contrib.rag.document_utils:Detected file. Returning file path...\n",
      "INFO:docling.document_converter:Going to convert document batch...\n",
      "/home/vscode/.local/lib/python3.10/site-packages/docling/models/easyocr_model.py:58: UserWarning: Deprecated field. Better to set the `accelerator_options.device` in `pipeline_options`. When `use_gpu and accelerator_options.device == AcceleratorDevice.CUDA` the GPU is used to run EasyOCR. Otherwise, EasyOCR runs in CPU.\n",
      "  warnings.warn(\n",
      "INFO:docling.utils.accelerator_utils:Accelerator device: 'cpu'\n",
      "INFO:docling.utils.accelerator_utils:Accelerator device: 'cpu'\n",
      "INFO:docling.pipeline.base_pipeline:Processing document Toast_financial_report.pdf\n",
      "INFO:docling.document_converter:Finished converting document Toast_financial_report.pdf in 24.34 sec.\n",
      "INFO:autogen.agentchat.contrib.rag.parser_utils:Document converted in 24.34 seconds.\n",
      "INFO:autogen.agentchat.contrib.rag.parser_utils:Document Toast_financial_report.pdf converted.\n",
      "Saved markdown output to: /workspaces/ag2/output_dir_path\n",
      "INFO:autogen.agentchat.contrib.rag.parser_utils:Saving HTML table to /workspaces/ag2/output_dir_path/Toast_financial_report-table-1.html\n",
      "INFO:autogen.agentchat.contrib.rag.parser_utils:Saving HTML table to /workspaces/ag2/output_dir_path/Toast_financial_report-table-2.html\n",
      "INFO:autogen.agentchat.contrib.rag.parser_utils:Saving HTML table to /workspaces/ag2/output_dir_path/Toast_financial_report-table-3.html\n",
      "INFO:autogen.agentchat.contrib.rag.parser_utils:Saving HTML table to /workspaces/ag2/output_dir_path/Toast_financial_report-table-4.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mUserAgent\u001b[0m (to DoclingParserAgent):\n",
      "\n",
      "\u001b[32m***** Response from calling tool (call_zb7cxuWeEmflKxds0HHmx9HV) *****\u001b[0m\n",
      "Error: `ResponseModel` is not fully defined; you should define `ConversionResult`, then call `ResponseModel.model_rebuild()`.\n",
      "\n",
      "For further information visit https://errors.pydantic.dev/2.10/u/class-not-fully-defined\n",
      "\u001b[32m**********************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mDoclingParserAgent\u001b[0m (to UserAgent):\n",
      "\n",
      "It seems there was an issue with parsing the PDF file. I'll need to troubleshoot the specific cause of the error, but unfortunately, I can't directly resolve software code issues here. Instead, you might want to verify the file path, format, and ensure that any dependencies or software components needed for parsing are correctly configured.\n",
      "\n",
      "If you want, I can attempt to parse another document or try using a different method if available.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatResult(chat_id=None, chat_history=[{'content': 'could you parse /workspaces/ag2/test/agentchat/contrib/graph_rag/Toast_financial_report.pdf and output to /workspaces/ag2/output_dir_path?', 'role': 'assistant', 'name': 'UserAgent'}, {'tool_calls': [{'id': 'call_zb7cxuWeEmflKxds0HHmx9HV', 'function': {'arguments': '{\"input_file_path\":\"/workspaces/ag2/test/agentchat/contrib/graph_rag/Toast_financial_report.pdf\",\"output_dir_path\":\"/workspaces/ag2/output_dir_path\"}', 'name': 'docling_parse_docs'}, 'type': 'function'}], 'content': None, 'role': 'assistant'}, {'content': 'Error: `ResponseModel` is not fully defined; you should define `ConversionResult`, then call `ResponseModel.model_rebuild()`.\\n\\nFor further information visit https://errors.pydantic.dev/2.10/u/class-not-fully-defined', 'tool_responses': [{'tool_call_id': 'call_zb7cxuWeEmflKxds0HHmx9HV', 'role': 'tool', 'content': 'Error: `ResponseModel` is not fully defined; you should define `ConversionResult`, then call `ResponseModel.model_rebuild()`.\\n\\nFor further information visit https://errors.pydantic.dev/2.10/u/class-not-fully-defined'}], 'role': 'tool', 'name': 'UserAgent'}, {'content': \"It seems there was an issue with parsing the PDF file. I'll need to troubleshoot the specific cause of the error, but unfortunately, I can't directly resolve software code issues here. Instead, you might want to verify the file path, format, and ensure that any dependencies or software components needed for parsing are correctly configured.\\n\\nIf you want, I can attempt to parse another document or try using a different method if available.\", 'role': 'user', 'name': 'DoclingParserAgent'}], summary=\"It seems there was an issue with parsing the PDF file. I'll need to troubleshoot the specific cause of the error, but unfortunately, I can't directly resolve software code issues here. Instead, you might want to verify the file path, format, and ensure that any dependencies or software components needed for parsing are correctly configured.\\n\\nIf you want, I can attempt to parse another document or try using a different method if available.\", cost={'usage_including_cached_inference': {'total_cost': 0.002395, 'gpt-4o-2024-08-06': {'cost': 0.002395, 'prompt_tokens': 410, 'completion_tokens': 137, 'total_tokens': 547}}, 'usage_excluding_cached_inference': {'total_cost': 0}}, human_input=['', 'exit'])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from autogen import UserProxyAgent\n",
    "\n",
    "user_agent = UserProxyAgent(\n",
    "    name=\"UserAgent\",\n",
    "    human_input_mode=\"ALWAYS\",\n",
    ")\n",
    "\n",
    "parser_tool.register_for_execution(user_agent)\n",
    "\n",
    "parser_agent = ParserAgent()\n",
    "\n",
    "\n",
    "user_agent.initiate_chat(\n",
    "    parser_agent,\n",
    "    message=\"could you parse /workspaces/ag2/test/agentchat/contrib/graph_rag/Toast_financial_report.pdf and output to /workspaces/ag2/output_dir_path?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vscode/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from copy import deepcopy\n",
    "from enum import Enum\n",
    "from typing import Any, Dict, List\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from autogen import ConversableAgent, SwarmResult, UserProxyAgent, initiate_swarm_chat, register_hand_off\n",
    "from autogen.agentchat.contrib.rag.docling_doc_ingest_agent import DoclingDocIngestAgent, DoclingQueryEngine\n",
    "from autogen.agentchat.contrib.swarm_agent import AfterWork, OnCondition, AfterWorkOption\n",
    "\n",
    "\n",
    "class QueryType(Enum):\n",
    "    RAG_QUERY = \"RAG_QUERY\"\n",
    "    COMMON_QUESTION = \"COMMON_QUESTION\"\n",
    "\n",
    "\n",
    "class Ingest(BaseModel):\n",
    "    path_or_url: str = Field(description=\"The path or URL of the documents to ingest.\")\n",
    "\n",
    "\n",
    "class Query(BaseModel):\n",
    "    query_type: QueryType = Field(description=\"The type of query to perform for the Document Agent.\")\n",
    "    query: str = Field(description=\"The query to perform for the Document Agent.\")\n",
    "\n",
    "\n",
    "class DocumentTask(BaseModel):\n",
    "    \"\"\"The structured output format for task decisions.\"\"\"\n",
    "\n",
    "    ingestions: list[Ingest] = Field(description=\"The list of documents to ingest.\")\n",
    "    queries: list[Query] = Field(description=\"The list of queries to perform.\")\n",
    "\n",
    "\n",
    "class DocumentTriageAgent(ConversableAgent):\n",
    "    def __init__(\n",
    "        self,\n",
    "        llm_config: Dict[str, Any],\n",
    "        *args,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        # Add the structured message to the LLM configuration\n",
    "        structured_config_list = deepcopy(llm_config)\n",
    "        for config in structured_config_list[\"config_list\"]:\n",
    "            config[\"response_format\"] = DocumentTask\n",
    "\n",
    "        super().__init__(\n",
    "            name=\"DocumentTriageAgent\",\n",
    "            system_message=(\n",
    "                \"You are a document triage agent.\"\n",
    "                \"You are responsible for deciding what type of task to perform from user requests.\"\n",
    "                \"When user uploads new documents or provide links of documents, you should add Ingest task to DocumentTask.\"\n",
    "                \"When user asks common questions, you should add 'COMMON_QUESTION' Query task to DocumentTask.\"\n",
    "                \"When user asks questions about information from existing documents, you add 'RAG_QUERY' Query task to DocumentTask.\"\n",
    "            ),\n",
    "            human_input_mode=\"NEVER\",\n",
    "            llm_config=structured_config_list,\n",
    "        )\n",
    "\n",
    "\n",
    "triage_agent = DocumentTriageAgent(llm_config=llm_config)\n",
    "\n",
    "\n",
    "def initiate_tasks(ingestions: list[Ingest], queries: list[Query], context_variables: dict) -> SwarmResult:\n",
    "    print(\"initiate_tasks context_variables\", context_variables)\n",
    "    if \"TaskInitiated\" in context_variables:\n",
    "        return SwarmResult(values=\"Task already initiated\", context_variables=context_variables)\n",
    "    context_variables[\"DocumentsToIngest\"] = ingestions\n",
    "    context_variables[\"QueriesToRun\"] = [query for query in queries]\n",
    "    context_variables[\"TaskInitiated\"] = True\n",
    "    return SwarmResult(\n",
    "        values=\"Updated context variables with task decisions\", \n",
    "        context_variables=context_variables,\n",
    "        agent=\"TaskManagerAgent\")\n",
    "\n",
    "\n",
    "task_manager_agent = ConversableAgent(\n",
    "    name=\"TaskManagerAgent\",\n",
    "    system_message=\"\"\"\n",
    "    You are a task manager agent. You would do the following:\n",
    "    1. You update the context variables based on the task decisions (DocumentTask) from the DocumentTriageAgent.\n",
    "    i.e. output\n",
    "    {\n",
    "        \"ingestions\": [\n",
    "            {\n",
    "                \"path_or_url\": \"path_or_url\"\n",
    "            }\n",
    "        ],\n",
    "        \"queries\": [\n",
    "            {\n",
    "                \"query_type\": \"RAG_QUERY\",\n",
    "                \"query\": \"query\"\n",
    "            }\n",
    "        ],\n",
    "        \"query_results\": [\n",
    "            {\n",
    "                \"query\": \"query\",\n",
    "                \"result\": \"result\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    2. You would hand off control to the appropriate agent based on the context variables.\n",
    "    \"\"\",\n",
    "    llm_config=llm_config,\n",
    "    functions=[initiate_tasks],\n",
    ")\n",
    "\n",
    "register_hand_off(\n",
    "    agent=triage_agent,\n",
    "    hand_to=[\n",
    "        # ON_CONDITION(task_manager_agent, \"After output task desicisions, transfer to task manager agent\"),\n",
    "        AfterWork(task_manager_agent),\n",
    "    ],\n",
    ")\n",
    "\n",
    "query_engine = DoclingQueryEngine()\n",
    "data_ingestion_agent = DoclingDocIngestAgent(\n",
    "    llm_config=llm_config,\n",
    "    query_engine=query_engine\n",
    ")\n",
    "\n",
    "def execute_rag_query(context_variables: dict) -> SwarmResult:\n",
    "    query = context_variables[\"QueriesToRun\"][0][\"query\"]\n",
    "    answer = query_engine.query(query)\n",
    "    context_variables[\"QueriesToRun\"].pop(0)\n",
    "    context_variables[\"CompletedTaskCount\"] += 1\n",
    "    context_variables[\"QueryResults\"].append({\"query\": query, \"result\": answer})\n",
    "    return SwarmResult(values=answer, context_variables=context_variables)\n",
    "\n",
    "query_agent = ConversableAgent(\n",
    "    name=\"QueryAgent\",\n",
    "    system_message=\"You are a query agent. You answer the user's questions only using the query function provided to you.\",\n",
    "    llm_config=llm_config,\n",
    "    functions=[execute_rag_query],\n",
    ")\n",
    "\n",
    "summary_agent = ConversableAgent(\n",
    "    name=\"SummaryAgent\",\n",
    "    system_message=\"You are a summary agent. You would generate a summary of all completed tasks and  answer the user's questions.\",\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "\n",
    "def has_ingest_tasks(agent: ConversableAgent, messages: List[Dict[str, Any]]) -> bool:\n",
    "    print(\"context_variables\", agent._context_variables)\n",
    "    return len(agent.get_context(\"DocumentsToIngest\")) > 0\n",
    "\n",
    "def has_query_tasks(agent: ConversableAgent, messages: List[Dict[str, Any]]) -> bool:\n",
    "    print(\"context_variables\", agent._context_variables)\n",
    "    if(len(agent.get_context(\"DocumentsToIngest\"))>0):\n",
    "        return False\n",
    "    return len(agent.get_context(\"QueriesToRun\")) > 0\n",
    "\n",
    "def summary_task(agent: ConversableAgent, messages: List[Dict[str, Any]]) -> bool:\n",
    "    return len(agent.get_context(\"DocumentsToIngest\")) == 0 and len(agent.get_context(\"QueriesToRun\")) == 0 and agent.get_context(\"CompletedTaskCount\")\n",
    "\n",
    "register_hand_off(\n",
    "    agent=task_manager_agent,\n",
    "    hand_to=[\n",
    "        OnCondition(\n",
    "            data_ingestion_agent, \n",
    "            \"If there are any DocumentsToIngest in context variables, transfer to data ingestion agent\",\n",
    "            available=has_ingest_tasks),\n",
    "        OnCondition(\n",
    "            query_agent, \n",
    "            \"If there are any QueriesToRun in context variables and no DocumentsToIngest, transfer to query_agent\",\n",
    "            available=has_query_tasks),\n",
    "        OnCondition(\n",
    "            summary_agent, \n",
    "            \"If there are no DocumentsToIngest or QueriesToRun in context variables, transfer to summary_agent\",\n",
    "            available=summary_task),\n",
    "        \n",
    "        # AfterWork(AfterWorkOption.TERMINATE),\n",
    "        \n",
    "    ]\n",
    ")\n",
    "\n",
    "register_hand_off(\n",
    "    agent=data_ingestion_agent,\n",
    "    hand_to=[\n",
    "        AfterWork(task_manager_agent),\n",
    "    ]\n",
    ")\n",
    "register_hand_off(\n",
    "    agent=query_agent,\n",
    "    hand_to=[\n",
    "        AfterWork(task_manager_agent),\n",
    "    ]\n",
    ")\n",
    "\n",
    "user_agent = UserProxyAgent(\n",
    "    name=\"UserAgent\",\n",
    "    system_message=\"A human admin.\",\n",
    "    human_input_mode=\"ALWAYS\",\n",
    ")\n",
    "\n",
    "register_hand_off(\n",
    "    agent=summary_agent,\n",
    "    hand_to=[\n",
    "        AfterWork(AfterWorkOption.TERMINATE),\n",
    "    ]\n",
    ")\n",
    "# chat_result = user_agent.initiate_chat(\n",
    "#     triage_agent,\n",
    "#     message=\"could you ingest /workspaces/ag2/test/agentchat/contrib/graph_rag/Toast_financial_report.pdf and summarise the FY2024 financials?\",\n",
    "# )\n",
    "\n",
    "# print(chat_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DocumentTriageAgent None\n",
      "TaskManagerAgent None\n",
      "DoclingDocIngestAgent None\n",
      "QueryAgent None\n",
      "SummaryAgent None\n"
     ]
    }
   ],
   "source": [
    "context_variables = {\n",
    "    \"CompletedTaskCount\": 0,\n",
    "    \"DocumentsToIngest\": [],\n",
    "    \"QueriesToRun\": [],\n",
    "    \"QueryResults\": [],\n",
    "}\n",
    "\n",
    "for agent in [triage_agent, task_manager_agent, data_ingestion_agent, query_agent, summary_agent]:\n",
    "    agent.reset()\n",
    "    agent._context_variables = None\n",
    "    print(agent.name, agent._context_variables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m_User\u001b[0m (to chat_manager):\n",
      "\n",
      "could you ingest /workspaces/ag2/test/agentchat/contrib/graph_rag/Toast_financial_report.pdf and summarise the FY2024 financials?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: DocumentTriageAgent\n",
      "\u001b[0m\n",
      "\u001b[33mDocumentTriageAgent\u001b[0m (to chat_manager):\n",
      "\n",
      "{\"ingestions\":[{\"path_or_url\":\"/workspaces/ag2/test/agentchat/contrib/graph_rag/Toast_financial_report.pdf\"}],\"queries\":[{\"query_type\":\"RAG_QUERY\",\"query\":\"Summarise the FY2024 financials from the Toast financial report.\"}]}\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: TaskManagerAgent\n",
      "\u001b[0m\n",
      "context_variables {'CompletedTaskCount': 0, 'DocumentsToIngest': [], 'QueriesToRun': [], 'QueryResults': []}\n",
      "context_variables {'CompletedTaskCount': 0, 'DocumentsToIngest': [], 'QueriesToRun': [], 'QueryResults': []}\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mTaskManagerAgent\u001b[0m (to chat_manager):\n",
      "\n",
      "\u001b[32m***** Suggested tool call (call_DGegAPFGZ3o6BXWNj0Kuc5HZ): initiate_tasks *****\u001b[0m\n",
      "Arguments: \n",
      "{\"ingestions\": [{\"path_or_url\": \"/workspaces/ag2/test/agentchat/contrib/graph_rag/Toast_financial_report.pdf\"}], \"queries\": [{\"query_type\": \"RAG_QUERY\", \"query\": \"Summarise the FY2024 financials from the Toast financial report.\"}]}\n",
      "\u001b[32m*******************************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: _Swarm_Tool_Executor\n",
      "\u001b[0m\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION initiate_tasks...\n",
      "Call ID: call_DGegAPFGZ3o6BXWNj0Kuc5HZ\n",
      "Input arguments: {'ingestions': [{'path_or_url': '/workspaces/ag2/test/agentchat/contrib/graph_rag/Toast_financial_report.pdf'}], 'queries': [{'query_type': 'RAG_QUERY', 'query': 'Summarise the FY2024 financials from the Toast financial report.'}], 'context_variables': {'CompletedTaskCount': 0, 'DocumentsToIngest': [], 'QueriesToRun': [], 'QueryResults': []}}\u001b[0m\n",
      "initiate_tasks context_variables {'CompletedTaskCount': 0, 'DocumentsToIngest': [], 'QueriesToRun': [], 'QueryResults': []}\n",
      "\u001b[33m_Swarm_Tool_Executor\u001b[0m (to chat_manager):\n",
      "\n",
      "\u001b[32m***** Response from calling tool (call_DGegAPFGZ3o6BXWNj0Kuc5HZ) *****\u001b[0m\n",
      "Updated context variables with task decisions\n",
      "\u001b[32m**********************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: TaskManagerAgent\n",
      "\u001b[0m\n",
      "context_variables {'CompletedTaskCount': 0, 'DocumentsToIngest': [{'path_or_url': '/workspaces/ag2/test/agentchat/contrib/graph_rag/Toast_financial_report.pdf'}], 'QueriesToRun': [{'query_type': 'RAG_QUERY', 'query': 'Summarise the FY2024 financials from the Toast financial report.'}], 'QueryResults': [], 'TaskInitiated': True}\n",
      "context_variables {'CompletedTaskCount': 0, 'DocumentsToIngest': [{'path_or_url': '/workspaces/ag2/test/agentchat/contrib/graph_rag/Toast_financial_report.pdf'}], 'QueriesToRun': [{'query_type': 'RAG_QUERY', 'query': 'Summarise the FY2024 financials from the Toast financial report.'}], 'QueryResults': [], 'TaskInitiated': True}\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mTaskManagerAgent\u001b[0m (to chat_manager):\n",
      "\n",
      "\u001b[32m***** Suggested tool call (call_7PKcOECjpV52QSPRcN8i1lYH): transfer_TaskManagerAgent_to_DoclingDocIngestAgent *****\u001b[0m\n",
      "Arguments: \n",
      "{}\n",
      "\u001b[32m*******************************************************************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: _Swarm_Tool_Executor\n",
      "\u001b[0m\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION transfer_TaskManagerAgent_to_DoclingDocIngestAgent...\n",
      "Call ID: call_7PKcOECjpV52QSPRcN8i1lYH\n",
      "Input arguments: {}\u001b[0m\n",
      "\u001b[33m_Swarm_Tool_Executor\u001b[0m (to chat_manager):\n",
      "\n",
      "\u001b[32m***** Response from calling tool (call_7PKcOECjpV52QSPRcN8i1lYH) *****\u001b[0m\n",
      "Swarm agent --> DoclingDocIngestAgent\n",
      "\u001b[32m**********************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: DoclingDocIngestAgent\n",
      "\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDoclingDocIngestAgent\u001b[0m (to chat_manager):\n",
      "\n",
      "\u001b[32m***** Suggested tool call (call_8TSbLAOGNytRyTe3sN7o5Spn): data_ingest_task *****\u001b[0m\n",
      "Arguments: \n",
      "{}\n",
      "\u001b[32m*********************************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: _Swarm_Tool_Executor\n",
      "\u001b[0m\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION data_ingest_task...\n",
      "Call ID: call_8TSbLAOGNytRyTe3sN7o5Spn\n",
      "Input arguments: {'context_variables': {'CompletedTaskCount': 0, 'DocumentsToIngest': [{'path_or_url': '/workspaces/ag2/test/agentchat/contrib/graph_rag/Toast_financial_report.pdf'}], 'QueriesToRun': [{'query_type': 'RAG_QUERY', 'query': 'Summarise the FY2024 financials from the Toast financial report.'}], 'QueryResults': [], 'TaskInitiated': True}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:autogen.agentchat.contrib.rag.document_utils:Error when checking if /workspaces/ag2/test/agentchat/contrib/graph_rag/Toast_financial_report.pdf is a valid URL: Invalid URL.\n",
      "INFO:autogen.agentchat.contrib.rag.document_utils:Detected file. Returning file path...\n",
      "INFO:docling.document_converter:Going to convert document batch...\n",
      "/home/vscode/.local/lib/python3.10/site-packages/docling/models/easyocr_model.py:58: UserWarning: Deprecated field. Better to set the `accelerator_options.device` in `pipeline_options`. When `use_gpu and accelerator_options.device == AcceleratorDevice.CUDA` the GPU is used to run EasyOCR. Otherwise, EasyOCR runs in CPU.\n",
      "  warnings.warn(\n",
      "INFO:docling.utils.accelerator_utils:Accelerator device: 'cpu'\n",
      "INFO:docling.utils.accelerator_utils:Accelerator device: 'cpu'\n",
      "INFO:docling.pipeline.base_pipeline:Processing document Toast_financial_report.pdf\n",
      "INFO:docling.document_converter:Finished converting document Toast_financial_report.pdf in 18.35 sec.\n",
      "INFO:autogen.agentchat.contrib.rag.parser_utils:Document converted in 18.36 seconds.\n",
      "INFO:autogen.agentchat.contrib.rag.parser_utils:Document Toast_financial_report.pdf converted.\n",
      "Saved markdown output to: output_dir\n",
      "INFO:autogen.agentchat.contrib.rag.parser_utils:Saving HTML table to output_dir/Toast_financial_report-table-1.html\n",
      "INFO:autogen.agentchat.contrib.rag.parser_utils:Saving HTML table to output_dir/Toast_financial_report-table-2.html\n",
      "INFO:autogen.agentchat.contrib.rag.parser_utils:Saving HTML table to output_dir/Toast_financial_report-table-3.html\n",
      "INFO:autogen.agentchat.contrib.rag.parser_utils:Saving HTML table to output_dir/Toast_financial_report-table-4.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m_Swarm_Tool_Executor\u001b[0m (to chat_manager):\n",
      "\n",
      "\u001b[32m***** Response from calling tool (call_8TSbLAOGNytRyTe3sN7o5Spn) *****\u001b[0m\n",
      "Error: DoclingQueryEngine.add_docs() got an unexpected keyword argument 'input_dir'\n",
      "\u001b[32m**********************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: DoclingDocIngestAgent\n",
      "\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDoclingDocIngestAgent\u001b[0m (to chat_manager):\n",
      "\n",
      "\u001b[32m***** Suggested tool call (call_AwIbWRnam7oqsVfIS2hiR8FA): data_ingest_task *****\u001b[0m\n",
      "Arguments: \n",
      "{}\n",
      "\u001b[32m*********************************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: _Swarm_Tool_Executor\n",
      "\u001b[0m\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION data_ingest_task...\n",
      "Call ID: call_AwIbWRnam7oqsVfIS2hiR8FA\n",
      "Input arguments: {'context_variables': {'CompletedTaskCount': 0, 'DocumentsToIngest': [{'path_or_url': '/workspaces/ag2/test/agentchat/contrib/graph_rag/Toast_financial_report.pdf'}], 'QueriesToRun': [{'query_type': 'RAG_QUERY', 'query': 'Summarise the FY2024 financials from the Toast financial report.'}], 'QueryResults': [], 'TaskInitiated': True}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:autogen.agentchat.contrib.rag.document_utils:Error when checking if /workspaces/ag2/test/agentchat/contrib/graph_rag/Toast_financial_report.pdf is a valid URL: Invalid URL.\n",
      "INFO:autogen.agentchat.contrib.rag.document_utils:Detected file. Returning file path...\n",
      "INFO:docling.document_converter:Going to convert document batch...\n",
      "/home/vscode/.local/lib/python3.10/site-packages/docling/models/easyocr_model.py:58: UserWarning: Deprecated field. Better to set the `accelerator_options.device` in `pipeline_options`. When `use_gpu and accelerator_options.device == AcceleratorDevice.CUDA` the GPU is used to run EasyOCR. Otherwise, EasyOCR runs in CPU.\n",
      "  warnings.warn(\n",
      "INFO:docling.utils.accelerator_utils:Accelerator device: 'cpu'\n",
      "INFO:docling.utils.accelerator_utils:Accelerator device: 'cpu'\n",
      "INFO:docling.pipeline.base_pipeline:Processing document Toast_financial_report.pdf\n",
      "INFO:docling.document_converter:Finished converting document Toast_financial_report.pdf in 32.49 sec.\n",
      "INFO:autogen.agentchat.contrib.rag.parser_utils:Document converted in 32.49 seconds.\n",
      "INFO:autogen.agentchat.contrib.rag.parser_utils:Document Toast_financial_report.pdf converted.\n",
      "Saved markdown output to: output_dir\n",
      "INFO:autogen.agentchat.contrib.rag.parser_utils:Saving HTML table to output_dir/Toast_financial_report-table-1.html\n",
      "INFO:autogen.agentchat.contrib.rag.parser_utils:Saving HTML table to output_dir/Toast_financial_report-table-2.html\n",
      "INFO:autogen.agentchat.contrib.rag.parser_utils:Saving HTML table to output_dir/Toast_financial_report-table-3.html\n",
      "INFO:autogen.agentchat.contrib.rag.parser_utils:Saving HTML table to output_dir/Toast_financial_report-table-4.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m_Swarm_Tool_Executor\u001b[0m (to chat_manager):\n",
      "\n",
      "\u001b[32m***** Response from calling tool (call_AwIbWRnam7oqsVfIS2hiR8FA) *****\u001b[0m\n",
      "Error: DoclingQueryEngine.add_docs() got an unexpected keyword argument 'input_dir'\n",
      "\u001b[32m**********************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: DoclingDocIngestAgent\n",
      "\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDoclingDocIngestAgent\u001b[0m (to chat_manager):\n",
      "\n",
      "\u001b[32m***** Suggested tool call (call_knPYapfEG3tiIJ7dk0AL7qtZ): data_ingest_task *****\u001b[0m\n",
      "Arguments: \n",
      "{}\n",
      "\u001b[32m*********************************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: _Swarm_Tool_Executor\n",
      "\u001b[0m\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION data_ingest_task...\n",
      "Call ID: call_knPYapfEG3tiIJ7dk0AL7qtZ\n",
      "Input arguments: {'context_variables': {'CompletedTaskCount': 0, 'DocumentsToIngest': [{'path_or_url': '/workspaces/ag2/test/agentchat/contrib/graph_rag/Toast_financial_report.pdf'}], 'QueriesToRun': [{'query_type': 'RAG_QUERY', 'query': 'Summarise the FY2024 financials from the Toast financial report.'}], 'QueryResults': [], 'TaskInitiated': True}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:autogen.agentchat.contrib.rag.document_utils:Error when checking if /workspaces/ag2/test/agentchat/contrib/graph_rag/Toast_financial_report.pdf is a valid URL: Invalid URL.\n",
      "INFO:autogen.agentchat.contrib.rag.document_utils:Detected file. Returning file path...\n",
      "INFO:docling.document_converter:Going to convert document batch...\n",
      "/home/vscode/.local/lib/python3.10/site-packages/docling/models/easyocr_model.py:58: UserWarning: Deprecated field. Better to set the `accelerator_options.device` in `pipeline_options`. When `use_gpu and accelerator_options.device == AcceleratorDevice.CUDA` the GPU is used to run EasyOCR. Otherwise, EasyOCR runs in CPU.\n",
      "  warnings.warn(\n",
      "INFO:docling.utils.accelerator_utils:Accelerator device: 'cpu'\n",
      "INFO:docling.utils.accelerator_utils:Accelerator device: 'cpu'\n",
      "INFO:docling.pipeline.base_pipeline:Processing document Toast_financial_report.pdf\n",
      "INFO:docling.document_converter:Finished converting document Toast_financial_report.pdf in 25.72 sec.\n",
      "INFO:autogen.agentchat.contrib.rag.parser_utils:Document converted in 25.72 seconds.\n",
      "INFO:autogen.agentchat.contrib.rag.parser_utils:Document Toast_financial_report.pdf converted.\n",
      "Saved markdown output to: output_dir\n",
      "INFO:autogen.agentchat.contrib.rag.parser_utils:Saving HTML table to output_dir/Toast_financial_report-table-1.html\n",
      "INFO:autogen.agentchat.contrib.rag.parser_utils:Saving HTML table to output_dir/Toast_financial_report-table-2.html\n",
      "INFO:autogen.agentchat.contrib.rag.parser_utils:Saving HTML table to output_dir/Toast_financial_report-table-3.html\n",
      "INFO:autogen.agentchat.contrib.rag.parser_utils:Saving HTML table to output_dir/Toast_financial_report-table-4.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m_Swarm_Tool_Executor\u001b[0m (to chat_manager):\n",
      "\n",
      "\u001b[32m***** Response from calling tool (call_knPYapfEG3tiIJ7dk0AL7qtZ) *****\u001b[0m\n",
      "Error: DoclingQueryEngine.add_docs() got an unexpected keyword argument 'input_dir'\n",
      "\u001b[32m**********************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: DoclingDocIngestAgent\n",
      "\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDoclingDocIngestAgent\u001b[0m (to chat_manager):\n",
      "\n",
      "It seems there's an issue with accessing the document ingestion tool, and I'm unable to ingest the document at the moment. If you have any alternative methods to share the document, please let me know, or I can try another approach if available.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: TaskManagerAgent\n",
      "\u001b[0m\n",
      "context_variables {'CompletedTaskCount': 0, 'DocumentsToIngest': [{'path_or_url': '/workspaces/ag2/test/agentchat/contrib/graph_rag/Toast_financial_report.pdf'}], 'QueriesToRun': [{'query_type': 'RAG_QUERY', 'query': 'Summarise the FY2024 financials from the Toast financial report.'}], 'QueryResults': [], 'TaskInitiated': True}\n",
      "context_variables {'CompletedTaskCount': 0, 'DocumentsToIngest': [{'path_or_url': '/workspaces/ag2/test/agentchat/contrib/graph_rag/Toast_financial_report.pdf'}], 'QueriesToRun': [{'query_type': 'RAG_QUERY', 'query': 'Summarise the FY2024 financials from the Toast financial report.'}], 'QueryResults': [], 'TaskInitiated': True}\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mTaskManagerAgent\u001b[0m (to chat_manager):\n",
      "\n",
      "It seems there was an issue with ingesting the document. Please ensure the file path is correct and accessible, or alternatively provide the document through another means if possible. Would you like to try a different approach or have any other document-related tasks I can help with?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Context Variables:\n",
      "{\n",
      "  \"CompletedTaskCount\": 0,\n",
      "  \"DocumentsToIngest\": [\n",
      "    {\n",
      "      \"path_or_url\": \"/workspaces/ag2/test/agentchat/contrib/graph_rag/Toast_financial_report.pdf\"\n",
      "    }\n",
      "  ],\n",
      "  \"QueriesToRun\": [\n",
      "    {\n",
      "      \"query_type\": \"RAG_QUERY\",\n",
      "      \"query\": \"Summarise the FY2024 financials from the Toast financial report.\"\n",
      "    }\n",
      "  ],\n",
      "  \"QueryResults\": [],\n",
      "  \"TaskInitiated\": true\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "chat_result, context_variables, last_speaker = initiate_swarm_chat(\n",
    "    initial_agent=triage_agent,  # Starting agent\n",
    "    agents=[triage_agent, task_manager_agent, data_ingestion_agent, query_agent, summary_agent],\n",
    "    messages=\"could you ingest /workspaces/ag2/test/agentchat/contrib/graph_rag/Toast_financial_report.pdf and summarise the FY2024 financials?\",\n",
    "    context_variables=context_variables,  # Context\n",
    "    after_work=AfterWork(AfterWorkOption.TERMINATE),  # Swarm-level after work hand off\n",
    ")\n",
    "\n",
    "print(f\"Context Variables:\\n{json.dumps(context_variables, indent=2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33muser\u001b[0m (to Document_Agent):\n",
      "\n",
      "could you ingest /workspaces/ag2/test/agentchat/contrib/graph_rag/Toast_financial_report.pdf and summarise the FY2024 financials?\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "DocumentAgent.generate_inner_swarm_reply() got multiple values for argument 'messages'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mautogen\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01magentchat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontrib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrag\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocument_agent\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DocumentAgent\n\u001b[1;32m      3\u001b[0m document_agent \u001b[38;5;241m=\u001b[39m DocumentAgent(\n\u001b[1;32m      4\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDocument_Agent\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      5\u001b[0m     llm_config\u001b[38;5;241m=\u001b[39mllm_config)\n\u001b[0;32m----> 6\u001b[0m \u001b[43mdocument_agent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcould you ingest /workspaces/ag2/test/agentchat/contrib/graph_rag/Toast_financial_report.pdf and summarise the FY2024 financials?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspaces/ag2/autogen/agentchat/conversable_agent.py:3341\u001b[0m, in \u001b[0;36mConversableAgent.run\u001b[0;34m(self, message, tools, executor_kwargs, max_turns, msg_to, clear_history, user_input)\u001b[0m\n\u001b[1;32m   3334\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_executor(\n\u001b[1;32m   3335\u001b[0m     executor_kwargs\u001b[38;5;241m=\u001b[39mexecutor_kwargs,\n\u001b[1;32m   3336\u001b[0m     tools\u001b[38;5;241m=\u001b[39mtools,\n\u001b[1;32m   3337\u001b[0m     agent_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   3338\u001b[0m     agent_human_input_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mALWAYS\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m user_input \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNEVER\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   3339\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[1;32m   3340\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m msg_to \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124magent\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 3341\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mexecutor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitiate_chat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclear_history\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclear_history\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_turns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_turns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3342\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3343\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitiate_chat(executor, message\u001b[38;5;241m=\u001b[39mmessage, clear_history\u001b[38;5;241m=\u001b[39mclear_history, max_turns\u001b[38;5;241m=\u001b[39mmax_turns)\n",
      "File \u001b[0;32m/workspaces/ag2/autogen/agentchat/conversable_agent.py:1494\u001b[0m, in \u001b[0;36mConversableAgent.initiate_chat\u001b[0;34m(self, recipient, clear_history, silent, cache, max_turns, summary_method, summary_args, message, **kwargs)\u001b[0m\n\u001b[1;32m   1492\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1493\u001b[0m         msg2send \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_init_message(message, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 1494\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg2send\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecipient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msilent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1495\u001b[0m summary \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_summarize_chat(\n\u001b[1;32m   1496\u001b[0m     summary_method,\n\u001b[1;32m   1497\u001b[0m     summary_args,\n\u001b[1;32m   1498\u001b[0m     recipient,\n\u001b[1;32m   1499\u001b[0m     cache\u001b[38;5;241m=\u001b[39mcache,\n\u001b[1;32m   1500\u001b[0m )\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m agent \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;28mself\u001b[39m, recipient]:\n",
      "File \u001b[0;32m/workspaces/ag2/autogen/agentchat/conversable_agent.py:1186\u001b[0m, in \u001b[0;36mConversableAgent.send\u001b[0;34m(self, message, recipient, request_reply, silent)\u001b[0m\n\u001b[1;32m   1184\u001b[0m valid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_append_oai_message(message, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massistant\u001b[39m\u001b[38;5;124m\"\u001b[39m, recipient, is_sending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m valid:\n\u001b[0;32m-> 1186\u001b[0m     \u001b[43mrecipient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreceive\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_reply\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1188\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1189\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMessage can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt be converted into a valid ChatCompletion message. Either content or function_call must be provided.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1190\u001b[0m     )\n",
      "File \u001b[0;32m/workspaces/ag2/autogen/agentchat/conversable_agent.py:1294\u001b[0m, in \u001b[0;36mConversableAgent.receive\u001b[0;34m(self, message, sender, request_reply, silent)\u001b[0m\n\u001b[1;32m   1292\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m request_reply \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (request_reply \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreply_at_receive[sender] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m   1293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m-> 1294\u001b[0m reply \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_reply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat_messages\u001b[49m\u001b[43m[\u001b[49m\u001b[43msender\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msender\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msender\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1295\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reply \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1296\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(reply, sender, silent\u001b[38;5;241m=\u001b[39msilent)\n",
      "File \u001b[0;32m/workspaces/ag2/autogen/agentchat/conversable_agent.py:2435\u001b[0m, in \u001b[0;36mConversableAgent.generate_reply\u001b[0;34m(self, messages, sender, **kwargs)\u001b[0m\n\u001b[1;32m   2433\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   2434\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_match_trigger(reply_func_tuple[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrigger\u001b[39m\u001b[38;5;124m\"\u001b[39m], sender):\n\u001b[0;32m-> 2435\u001b[0m     final, reply \u001b[38;5;241m=\u001b[39m \u001b[43mreply_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msender\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msender\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreply_func_tuple\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconfig\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2436\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m logging_enabled():\n\u001b[1;32m   2437\u001b[0m         log_event(\n\u001b[1;32m   2438\u001b[0m             \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   2439\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreply_func_executed\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2443\u001b[0m             reply\u001b[38;5;241m=\u001b[39mreply,\n\u001b[1;32m   2444\u001b[0m         )\n",
      "\u001b[0;31mTypeError\u001b[0m: DocumentAgent.generate_inner_swarm_reply() got multiple values for argument 'messages'"
     ]
    }
   ],
   "source": [
    "from autogen.agentchat.contrib.rag.document_agent import DocumentAgent\n",
    "\n",
    "document_agent = DocumentAgent(\n",
    "    llm_config=llm_config)\n",
    "document_agent.run(\"could you ingest /workspaces/ag2/test/agentchat/contrib/graph_rag/Toast_financial_report.pdf and summarise the FY2024 financials?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Description                           | Year Ended Jan 28, 2024 | Year Ended Jan 29, 2023 |\n",
    "|---------------------------------------|-------------------------|-------------------------|\n",
    "| **Revenue**                           | 100.0 %                 | 100.0 %                 |\n",
    "| Cost of revenue                       | 27.3                    | 43.1                    |\n",
    "| **Gross profit**                      | 72.7                    | 56.9                    |\n",
    "| **Operating expenses**                |                         |                         |\n",
    "| Research and development              | 14.2                    | 27.2                    |\n",
    "| Sales, general and administrative     | 4.4                     | 9.1                     |\n",
    "| Acquisition termination cost          |                        | 5.0                     |\n",
    "| Total operating expenses              | 18.6                    | 41.3                    |\n",
    "| **Operating income**                  | 54.1                    | 15.6                    |\n",
    "| Interest income                       | 1.4                     | 1.0                     |\n",
    "| Interest expense                      | (0.4)                   | (1.0)                   |\n",
    "| Other, net                            | 0.4                     | (0.1)                   |\n",
    "| **Other income (expense), net**       | 1.4                     | (0.1)                   |\n",
    "| **Income before income tax**          | 55.5                    | 15.5                    |\n",
    "| Income tax expense (benefit)          | 6.6                     | (0.7)                   |\n",
    "| **Net income**                        | 48.9 %                  | 16.2 %                  |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| | Jan 28, 2024 | | | Jan 29, 2023 | | |\n",
    "|---|---|---|---|---|---|---|\n",
    "| | Gross Carrying Amount | Accumulated Amortization | Net Carrying Amount | Gross Carrying Amount | Accumulated Amortization | Net Carrying Amount |\n",
    "| | | | (In millions) | | | |\n",
    "| Acquisition-related intangible assets (1) | $ 2,642 | $ (1,720) | $ 922 | $ 3,093 | $ (1,614) | $ 1,479 |\n",
    "| Patents and licensed technology | 449 | (259) | 190 | 446 | (249) | 197 |\n",
    "| Total intangible assets | $ 3,091 | $ (1,979) | $ 1,112 | $ 3,539 | $ (1,863) | $ 1,676 |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
